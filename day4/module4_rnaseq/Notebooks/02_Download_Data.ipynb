{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download fastq files from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from ENCODE\n",
    "\n",
    "This is how you would download data from the [ENCODE](https://www.encodeproject.org/) website. There are many different experiments and datasets available here. You can download both raw and fully processed data. Let's take a look at HepG2 cell line conditions:\n",
    "- knockdown of TARDBP (or TDP-43) data [here](https://www.encodeproject.org/experiments/ENCSR527QNC/)\n",
    "- control [here](https://www.encodeproject.org/experiments/ENCSR264TUE/) \n",
    "\n",
    "Let's find the fastq files now. \n",
    "- Go down to the \"Files\" section\n",
    "- Click on the \"File details\" tab \n",
    "- Under the \"Raw sequencing data\" we can find our fastq files \n",
    "- When you have found the link to the fastq files, right click on the download link and select \"Copy Link Address\". \n",
    "\n",
    "### Example:\n",
    "\n",
    "```\n",
    "$ wget https://www.encodeproject.org/files/ENCFF682WVW/@@download/ENCFF682WVW.fastq.gz\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- ENCODE also has processed data files that have already been aligned (to different genome builds GRCh38 V28 or hg19) and quantified. In order to run the entire pipeline, we only want the raw reads stored in fastq.  \n",
    "\n",
    "- *Keep in mind* that this data is paired-end, so there are two reads per dataset (R1 and R2). So you will need to download two files per sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data already uploaded to the GitHub\n",
    "\n",
    "If TSCC were online this week, then it would cause a backlog on the login node if all of us were to download ENCODE data using `wget`! For the purposes of this class, we'll be using pre-loaded data that we've uploaded to GitHub for this week.\n",
    "\n",
    "The FASTQ files for this \n",
    "\n",
    "fastq files are located in this folder:\n",
    "\n",
    "```\n",
    "/cmm262-2020/Module_2/Data/\n",
    "```\n",
    "\n",
    "Here you will find fastq file named:\n",
    "\n",
    "```\n",
    "sample.fastq.gz\n",
    "```\n",
    "\n",
    "This is a subsampling of the ENCODE dataset that we featured in the previous section. \n",
    "\n",
    "### Extra Practice for `wget`\n",
    "\n",
    "If you're interested, you can download this data to your Jupyter notebook by clicking on the fastq file on GitHub, and then right-clicking the `Download` button. This will give you a link that you can then use for the `wget` command:\n",
    "\n",
    "```\n",
    "$ wget https://github.com/biom262/cmm262-2020/raw/master/Module_2/Data/sample.fastq.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why ENCODE?\n",
    "\n",
    "We're using an ENCODE dataset because they are well standardized and monitored for quality, easy to access, and useful for pairwise comparison. However, if you would like to find out how to download other publicly available data, such as datasets available on the [Gene Expression Omnibus](\"https://www.ncbi.nlm.nih.gov/geo/\") (GEO), check out this [notebook](\"https://github.com/biom262/biom262-2018/blob/master/Module1_Unix_RNASeq/Tutorials/Download_data_from_GEO.ipynb\") in the Tutorials section."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
